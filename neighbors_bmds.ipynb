{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-09T17:26:20.326695Z",
     "start_time": "2024-06-09T17:26:19.090118Z"
    }
   },
   "source": [
    "from utils.bmds import BMDSTrainer\n",
    "from utils.nn import create_mlp_layers\n",
    "import torch\n",
    "from sklearn.neighbors import BallTree\n",
    "from utils.preprocessing import check_tensor\n",
    "from utils.distributions import exponential_log_prob\n",
    "from typing import Any, Optional, Callable\n",
    "from torch import nn"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "n = 60000\n",
    "k = 100\n",
    "d_latent = 2\n",
    "d = 10\n",
    "noise_coef = 1e-3\n",
    "batch_size = 128"
   ],
   "id": "fe94af2438a31a67"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T18:27:25.056799Z",
     "start_time": "2024-06-09T18:27:25.019727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BMDS(nn.Module):\n",
    "    default_create_layers_kwargs: dict[str, Any] = {\n",
    "        'activation': 'PReLU',\n",
    "        'use_batch_norm': False,\n",
    "        'last_layer_activation':  True,\n",
    "        'last_layer_batch_norm': True,\n",
    "    }\n",
    "    \n",
    "    def __init__(\n",
    "            self,\n",
    "            dist,\n",
    "            neighbors,\n",
    "            batch_size,\n",
    "            input_dim: int,\n",
    "            n: int,\n",
    "            *,\n",
    "            n_layers: int = 2,\n",
    "            hidden_dim: int = 1000,\n",
    "            embedding_dim: int = 100,\n",
    "            create_layers: Optional[Callable[..., list[nn.Module]]] = None,\n",
    "            **kwargs: Any,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dist_sqr = check_tensor(dist).pow(2)\n",
    "        self.neighbors = check_tensor(neighbors)\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.obj_idx = torch.arange(batch_size).repeat(dist.shape[1], 1).T.reshape(-1)\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n = n\n",
    "\n",
    "        if create_layers is None:\n",
    "            create_layers = create_mlp_layers\n",
    "            kwargs = {**self.default_create_layers_kwargs, **kwargs}\n",
    "\n",
    "        head_layers = create_layers(input_dim, [hidden_dim] * (n_layers - 1), hidden_dim, **kwargs)\n",
    "\n",
    "        self.head = nn.Sequential(*head_layers)\n",
    "\n",
    "        self.mu = nn.Parameter(torch.randn(hidden_dim, embedding_dim) / hidden_dim)\n",
    "        self.sigma = nn.Parameter(torch.randn(hidden_dim, embedding_dim) / hidden_dim)\n",
    "    \n",
    "    def forward(self, inp):\n",
    "        head = self.head(inp)\n",
    "        return head @ self.mu, (head.pow(2) @ self.sigma.pow(2)).pow(0.5)\n",
    "    \n",
    "    def loss(self, batch):\n",
    "        idx1, idx2, true_dist_sqr = batch.values()\n",
    "        \n",
    "        mu1, sigma1 = self(self.get_inp(idx1))\n",
    "        mu2, sigma2 = self(self.get_inp(idx2))\n",
    "        \n",
    "        dist_sqr = (mu1 - mu2 + torch.randn_like(mu1) * (sigma1.pow(2) + sigma2.pow(2)).pow(0.5)).pow(2).mean(1)\n",
    "        \n",
    "        log_prob = exponential_log_prob(true_dist_sqr.pow(2), dist_sqr).mean()\n",
    "        reg = (torch.log(self.mu.pow(2).mean(0) + self.sigma.pow(2).mean(0)).sum() * self.hidden_dim - torch.log(self.sigma.pow(2)).sum()) / self.n / 2\n",
    "        \n",
    "        return {'loss': -log_prob + reg, 'log_prob': log_prob, 'reg': reg}\n",
    "        \n",
    "    def get_inp(self, idx):\n",
    "        neighbors_idx = self.neighbors[idx].reshape(-1)\n",
    "        neighbors_dist_sqr = self.dist_sqr[idx].reshape(-1)\n",
    "        \n",
    "        return torch.sparse_coo_tensor(\n",
    "            indices=torch.stack((self.obj_idx, neighbors_idx)),\n",
    "            values=neighbors_dist_sqr,\n",
    "            size=(self.batch_size, self.input_dim),\n",
    "        )\n",
    "    \n",
    "    \n",
    "class NeighborsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dist, neighbors):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.object_idx = torch.arange(dist.shape[0]).repeat(dist.shape[1], 1).T.reshape(-1)\n",
    "        self.neighbors_idx = check_tensor(neighbors, dtype=torch.int32).reshape(-1)\n",
    "        self.dist_sqr = (check_tensor(dist).reshape(-1) / dist.max()).pow(2)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.dist_sqr.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {'idx1': self.object_idx[idx], 'idx2': self.neighbors_idx[idx], 'dist_sqr': self.dist_sqr[idx]}\n",
    "    \n",
    "    \n",
    "def create_generator(dataset: torch.utils.data.Dataset, batch_size: int = 128, shuffle: bool = True, drop_last: bool = True, **kwargs):\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, **kwargs)\n",
    "    while True:\n",
    "        yield from loader"
   ],
   "id": "15e52656c17dd3e6",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "latent_data = torch.randn(n, d_latent)\n",
    "data = latent_data @ torch.randn(d_latent, d) + torch.randn(n, d) * noise_coef\n",
    "\n",
    "def query(data_point, *, ball_tree, n_neighbors):\n",
    "    return ball_tree.query(data_point.reshape(1, -1), k=n_neighbors + 1)\n",
    "\n",
    "\n",
    "def find_neighbors(data, n_neighbors: int, dist_fn=None):\n",
    "    if dist_fn is None:\n",
    "        ball_tree = BallTree(data, leaf_size=1, metric='euclidean')\n",
    "        distances, neighbors = ball_tree.query(data, k=n_neighbors + 1)\n",
    "        return distances[:, 1:], neighbors[:, 1:]\n",
    "    \n",
    "distances, neighbors = find_neighbors(data, k)"
   ],
   "id": "46bad6982bc1c920"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "dataset = NeighborsDataset(distances, neighbors)\n",
    "bmds = BMDS(distances, neighbors, batch_size, n, len(dataset))\n",
    "bmds_trainer = BMDSTrainer(bmds)\n",
    "\n",
    "bmds_trainer.train(create_generator(dataset), project_name='bmds mnist', experiment_name='first trial', total_iters=100000)"
   ],
   "id": "bad67c265f4ad829"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3642d9bbd676eaff"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
